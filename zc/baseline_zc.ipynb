{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference:\n",
    "\n",
    "https://blog.csdn.net/jiongnima/article/details/80033169\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf #导入tensorflow\n",
    "from tensorflow.examples.tutorials.mnist import input_data #导入手写数字数据集\n",
    "import numpy as np #导入numpy\n",
    "import matplotlib.pyplot as plt #plt是绘图工具，在训练过程中用于输出可视化结果\n",
    "import matplotlib.gridspec as gridspec #gridspec是图片排列工具，在训练过程中用于输出可视化结果\n",
    "import os #导入os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "The checkpoint has been created.\n",
      "Iter: 0\n",
      "D loss: 2.028\n",
      "G_loss: 1.553\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 1000\n",
      "D loss: 0.007508\n",
      "G_loss: 9.171\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 2000\n",
      "D loss: 0.01378\n",
      "G_loss: 6.676\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 3000\n",
      "D loss: 0.06766\n",
      "G_loss: 6.176\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 4000\n",
      "D loss: 0.06966\n",
      "G_loss: 4.929\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 5000\n",
      "D loss: 0.1121\n",
      "G_loss: 5.336\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 6000\n",
      "D loss: 0.3943\n",
      "G_loss: 4.049\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 7000\n",
      "D loss: 0.4412\n",
      "G_loss: 4.498\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 8000\n",
      "D loss: 0.4062\n",
      "G_loss: 3.942\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 9000\n",
      "D loss: 0.4144\n",
      "G_loss: 3.328\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 10000\n",
      "D loss: 0.4968\n",
      "G_loss: 2.739\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 11000\n",
      "D loss: 0.6928\n",
      "G_loss: 2.612\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 12000\n",
      "D loss: 0.5461\n",
      "G_loss: 2.501\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 13000\n",
      "D loss: 0.4926\n",
      "G_loss: 2.648\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 14000\n",
      "D loss: 0.7257\n",
      "G_loss: 2.28\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 15000\n",
      "D loss: 0.5529\n",
      "G_loss: 2.546\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 16000\n",
      "D loss: 0.572\n",
      "G_loss: 2.719\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 17000\n",
      "D loss: 0.6785\n",
      "G_loss: 2.252\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 18000\n",
      "D loss: 0.7436\n",
      "G_loss: 2.411\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 19000\n",
      "D loss: 0.6771\n",
      "G_loss: 2.539\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 20000\n",
      "D loss: 0.6128\n",
      "G_loss: 2.472\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 21000\n",
      "D loss: 0.5986\n",
      "G_loss: 2.564\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 22000\n",
      "D loss: 0.7345\n",
      "G_loss: 2.585\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 23000\n",
      "D loss: 0.8397\n",
      "G_loss: 2.645\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 24000\n",
      "D loss: 0.5437\n",
      "G_loss: 2.631\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 25000\n",
      "D loss: 0.6152\n",
      "G_loss: 2.147\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 26000\n",
      "D loss: 0.7899\n",
      "G_loss: 2.763\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 27000\n",
      "D loss: 0.5958\n",
      "G_loss: 2.416\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 28000\n",
      "D loss: 0.6147\n",
      "G_loss: 2.804\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 29000\n",
      "D loss: 0.5504\n",
      "G_loss: 2.574\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 30000\n",
      "D loss: 0.5747\n",
      "G_loss: 2.142\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 31000\n",
      "D loss: 0.8345\n",
      "G_loss: 2.712\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 32000\n",
      "D loss: 0.56\n",
      "G_loss: 2.623\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 33000\n",
      "D loss: 0.6185\n",
      "G_loss: 2.325\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 34000\n",
      "D loss: 0.7114\n",
      "G_loss: 2.838\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 35000\n",
      "D loss: 0.6984\n",
      "G_loss: 2.348\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 36000\n",
      "D loss: 0.6977\n",
      "G_loss: 2.8\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 37000\n",
      "D loss: 0.6383\n",
      "G_loss: 2.582\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 38000\n",
      "D loss: 0.5567\n",
      "G_loss: 2.46\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 39000\n",
      "D loss: 0.6093\n",
      "G_loss: 3.003\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 40000\n",
      "D loss: 0.6283\n",
      "G_loss: 2.569\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 41000\n",
      "D loss: 0.7163\n",
      "G_loss: 2.561\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 42000\n",
      "D loss: 0.6166\n",
      "G_loss: 2.468\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 43000\n",
      "D loss: 0.5365\n",
      "G_loss: 2.445\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 44000\n",
      "D loss: 0.5852\n",
      "G_loss: 2.564\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 45000\n",
      "D loss: 0.6026\n",
      "G_loss: 2.511\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 46000\n",
      "D loss: 0.6489\n",
      "G_loss: 2.501\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 47000\n",
      "D loss: 0.4737\n",
      "G_loss: 2.418\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 48000\n",
      "D loss: 0.5921\n",
      "G_loss: 2.504\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 49000\n",
      "D loss: 0.5189\n",
      "G_loss: 2.347\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 50000\n",
      "D loss: 0.6156\n",
      "G_loss: 2.644\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 51000\n",
      "D loss: 0.7119\n",
      "G_loss: 2.215\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 52000\n",
      "D loss: 0.5458\n",
      "G_loss: 2.555\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 53000\n",
      "D loss: 0.6174\n",
      "G_loss: 2.651\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 54000\n",
      "D loss: 0.6006\n",
      "G_loss: 2.53\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 55000\n",
      "D loss: 0.6221\n",
      "G_loss: 2.035\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 56000\n",
      "D loss: 0.5639\n",
      "G_loss: 2.305\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 57000\n",
      "D loss: 0.5468\n",
      "G_loss: 2.709\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 58000\n",
      "D loss: 0.5315\n",
      "G_loss: 2.612\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 59000\n",
      "D loss: 0.599\n",
      "G_loss: 2.419\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 60000\n",
      "D loss: 0.519\n",
      "G_loss: 2.731\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 61000\n",
      "D loss: 0.5634\n",
      "G_loss: 2.548\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 62000\n",
      "D loss: 0.6694\n",
      "G_loss: 2.8\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 63000\n",
      "D loss: 0.6096\n",
      "G_loss: 2.371\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 64000\n",
      "D loss: 0.6764\n",
      "G_loss: 2.278\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 65000\n",
      "D loss: 0.6553\n",
      "G_loss: 2.373\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 66000\n",
      "D loss: 0.6423\n",
      "G_loss: 2.418\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 67000\n",
      "D loss: 0.6887\n",
      "G_loss: 2.052\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 68000\n",
      "D loss: 0.7247\n",
      "G_loss: 2.354\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 69000\n",
      "D loss: 0.7745\n",
      "G_loss: 2.401\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 70000\n",
      "D loss: 0.6745\n",
      "G_loss: 2.408\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 71000\n",
      "D loss: 0.6441\n",
      "G_loss: 2.217\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 72000\n",
      "D loss: 0.6853\n",
      "G_loss: 2.488\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 73000\n",
      "D loss: 0.6146\n",
      "G_loss: 2.799\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 74000\n",
      "D loss: 0.6259\n",
      "G_loss: 2.196\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 75000\n",
      "D loss: 0.5319\n",
      "G_loss: 2.488\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 76000\n",
      "D loss: 0.6485\n",
      "G_loss: 2.223\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 77000\n",
      "D loss: 0.6524\n",
      "G_loss: 2.567\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 78000\n",
      "D loss: 0.5369\n",
      "G_loss: 2.16\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 79000\n",
      "D loss: 0.5032\n",
      "G_loss: 2.682\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 80000\n",
      "D loss: 0.6694\n",
      "G_loss: 2.416\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 81000\n",
      "D loss: 0.6849\n",
      "G_loss: 2.486\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 82000\n",
      "D loss: 0.6142\n",
      "G_loss: 2.239\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 83000\n",
      "D loss: 0.5417\n",
      "G_loss: 2.436\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 84000\n",
      "D loss: 0.6145\n",
      "G_loss: 2.701\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 85000\n",
      "D loss: 0.6358\n",
      "G_loss: 2.247\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 86000\n",
      "D loss: 0.5888\n",
      "G_loss: 2.066\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 87000\n",
      "D loss: 0.5318\n",
      "G_loss: 2.609\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 88000\n",
      "D loss: 0.4107\n",
      "G_loss: 2.747\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 89000\n",
      "D loss: 0.5355\n",
      "G_loss: 2.345\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 90000\n",
      "D loss: 0.4724\n",
      "G_loss: 2.647\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 91000\n",
      "D loss: 0.5466\n",
      "G_loss: 2.672\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 92000\n",
      "D loss: 0.4876\n",
      "G_loss: 2.775\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 93000\n",
      "D loss: 0.4503\n",
      "G_loss: 2.51\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 94000\n",
      "D loss: 0.6374\n",
      "G_loss: 2.185\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 95000\n",
      "D loss: 0.5264\n",
      "G_loss: 2.536\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 96000\n",
      "D loss: 0.4932\n",
      "G_loss: 2.595\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 97000\n",
      "D loss: 0.6297\n",
      "G_loss: 2.283\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 98000\n",
      "D loss: 0.5149\n",
      "G_loss: 2.708\n",
      "\n",
      "The checkpoint has been created.\n",
      "Iter: 99000\n",
      "D loss: 0.4591\n",
      "G_loss: 2.039\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def save(saver, sess, logdir, step): #保存模型的save函数\n",
    "   model_name = 'model' #模型名前缀\n",
    "   checkpoint_path = os.path.join(logdir, model_name) #保存路径\n",
    "   saver.save(sess, checkpoint_path, global_step=step) #保存模型\n",
    "   print('The checkpoint has been created.')\n",
    " \n",
    "def xavier_init(size): #初始化参数时使用的xavier_init函数\n",
    "    in_dim = size[0] \n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.) #初始化标准差\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev) #返回初始化的结果\n",
    " \n",
    "X = tf.placeholder(tf.float32, shape=[None, 784]) #X表示真的样本(即真实的手写数字)\n",
    "\n",
    "D_W1 = tf.Variable(xavier_init([784, 128])) #表示使用xavier方式初始化的判别器的D_W1参数，是一个784行128列的矩阵\n",
    "D_b1 = tf.Variable(tf.zeros(shape=[128])) #表示全零方式初始化的判别器的D_1参数，是一个长度为128的向量\n",
    " \n",
    "D_W2 = tf.Variable(xavier_init([128, 1])) #表示使用xavier方式初始化的判别器的D_W2参数，是一个128行1列的矩阵\n",
    "D_b2 = tf.Variable(tf.zeros(shape=[1])) ##表示全零方式初始化的判别器的D_1参数，是一个长度为1的向量\n",
    " \n",
    "theta_D = [D_W1, D_W2, D_b1, D_b2] #theta_D表示判别器的可训练参数集合\n",
    " \n",
    " \n",
    "Z = tf.placeholder(tf.float32, shape=[None, 100]) #Z表示生成器的输入(在这里是噪声)，是一个N列100行的矩阵\n",
    " \n",
    "G_W1 = tf.Variable(xavier_init([100, 128])) #表示使用xavier方式初始化的生成器的G_W1参数，是一个100行128列的矩阵\n",
    "G_b1 = tf.Variable(tf.zeros(shape=[128])) #表示全零方式初始化的生成器的G_b1参数，是一个长度为128的向量\n",
    " \n",
    "G_W2 = tf.Variable(xavier_init([128, 784])) #表示使用xavier方式初始化的生成器的G_W2参数，是一个128行784列的矩阵\n",
    "G_b2 = tf.Variable(tf.zeros(shape=[784])) #表示全零方式初始化的生成器的G_b2参数，是一个长度为784的向量\n",
    " \n",
    "theta_G = [G_W1, G_W2, G_b1, G_b2] #theta_G表示生成器的可训练参数集合\n",
    " \n",
    " \n",
    "def sample_Z(m, n): #生成维度为[m, n]的随机噪声作为生成器G的输入\n",
    "    return np.random.uniform(-1., 1., size=[m, n])\n",
    " \n",
    " \n",
    "def generator(z): #生成器，z的维度为[N, 100]\n",
    "    G_h1 = tf.nn.relu(tf.matmul(z, G_W1) + G_b1) #输入的随机噪声乘以G_W1矩阵加上偏置G_b1，G_h1维度为[N, 128]\n",
    "    G_log_prob = tf.matmul(G_h1, G_W2) + G_b2 #G_h1乘以G_W2矩阵加上偏置G_b2，G_log_prob维度为[N, 784]\n",
    "    G_prob = tf.nn.sigmoid(G_log_prob) #G_log_prob经过一个sigmoid函数，G_prob维度为[N, 784]\n",
    " \n",
    "    return G_prob #返回G_prob\n",
    " \n",
    " \n",
    "def discriminator(x): #判别器，x的维度为[N, 784]\n",
    "    D_h1 = tf.nn.relu(tf.matmul(x, D_W1) + D_b1) #输入乘以D_W1矩阵加上偏置D_b1，D_h1维度为[N, 128]\n",
    "    D_logit = tf.matmul(D_h1, D_W2) + D_b2 #D_h1乘以D_W2矩阵加上偏置D_b2，D_logit维度为[N, 1]\n",
    "    D_prob = tf.nn.sigmoid(D_logit) #D_logit经过一个sigmoid函数，D_prob维度为[N, 1]\n",
    " \n",
    "    return D_prob, D_logit #返回D_prob, D_logit\n",
    " \n",
    " \n",
    "def plot(samples): #保存图片时使用的plot函数\n",
    "    fig = plt.figure(figsize=(4, 4)) #初始化一个4行4列包含16张子图像的图片\n",
    "    gs = gridspec.GridSpec(4, 4) #调整子图的位置\n",
    "    gs.update(wspace=0.05, hspace=0.05) #置子图间的间距\n",
    " \n",
    "    for i, sample in enumerate(samples): #依次将16张子图填充进需要保存的图像\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        plt.imshow(sample.reshape(28, 28), cmap='Greys_r')\n",
    " \n",
    "    return fig\n",
    " \n",
    " \n",
    "G_sample = generator(Z) #取得生成器的生成结果\n",
    "D_real, D_logit_real = discriminator(X) #取得判别器判别的真实手写数字的结果\n",
    "D_fake, D_logit_fake = discriminator(G_sample) #取得判别器判别的生成的手写数字的结果\n",
    " \n",
    "D_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_real, labels=tf.ones_like(D_logit_real))) #对判别器对真实样本的判别结果计算误差(将结果与1比较)\n",
    "D_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.zeros_like(D_logit_fake))) #对判别器对虚假样本(即生成器生成的手写数字)的判别结果计算误差(将结果与0比较)\n",
    "D_loss = D_loss_real + D_loss_fake #判别器的误差\n",
    "G_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=D_logit_fake, labels=tf.ones_like(D_logit_fake))) #生成器的误差(将判别器返回的对虚假样本的判别结果与1比较)\n",
    " \n",
    "dreal_loss_sum = tf.summary.scalar(\"dreal_loss\", D_loss_real) #记录判别器判别真实样本的误差\n",
    "dfake_loss_sum = tf.summary.scalar(\"dfake_loss\", D_loss_fake) #记录判别器判别虚假样本的误差\n",
    "d_loss_sum = tf.summary.scalar(\"d_loss\", D_loss) #记录判别器的误差\n",
    "g_loss_sum = tf.summary.scalar(\"g_loss\", G_loss) #记录生成器的误差\n",
    " \n",
    "summary_writer = tf.summary.FileWriter('snapshots/', graph=tf.get_default_graph()) #日志记录器\n",
    " \n",
    "D_solver = tf.train.AdamOptimizer().minimize(D_loss, var_list=theta_D) #判别器的训练器\n",
    "G_solver = tf.train.AdamOptimizer().minimize(G_loss, var_list=theta_G) #生成器的训练器\n",
    " \n",
    "mb_size = 128 #训练的batch_size\n",
    "Z_dim = 100 #生成器输入的随机噪声的列的维度\n",
    " \n",
    "mnist = input_data.read_data_sets('../../MNIST_data', one_hot=True) #mnist是手写数字数据集\n",
    " \n",
    "sess = tf.Session() #会话层\n",
    "sess.run(tf.global_variables_initializer()) #初始化所有可训练参数\n",
    " \n",
    "if not os.path.exists('out/'): #初始化训练过程中的可视化结果的输出文件夹\n",
    "    os.makedirs('out/')\n",
    " \n",
    "if not os.path.exists('snapshots/'): #初始化训练过程中的模型保存文件夹\n",
    "    os.makedirs('snapshots/')\n",
    " \n",
    "saver = tf.train.Saver(var_list=tf.global_variables(), max_to_keep=50) #模型的保存器\n",
    " \n",
    "i = 0 #训练过程中保存的可视化结果的索引\n",
    " \n",
    "for it in range(1000000): #训练100万次\n",
    "    if it % 1000 == 0: #每训练1000次就保存一下结果\n",
    "        samples = sess.run(G_sample, feed_dict={Z: sample_Z(16, Z_dim)})\n",
    " \n",
    "        fig = plot(samples) #通过plot函数生成可视化结果\n",
    "        plt.savefig('out/{}.png'.format(str(i).zfill(3)), bbox_inches='tight') #保存可视化结果\n",
    "        i += 1\n",
    "        plt.close(fig)\n",
    " \n",
    "    X_mb, _ = mnist.train.next_batch(mb_size) #得到训练一个batch所需的真实手写数字(作为判别器的输入)\n",
    " \n",
    "    #下面是得到训练一次的结果，通过sess来run出来\n",
    "    _, D_loss_curr, dreal_loss_sum_value, dfake_loss_sum_value, d_loss_sum_value = sess.run([D_solver, D_loss, dreal_loss_sum, dfake_loss_sum, d_loss_sum], feed_dict={X: X_mb, Z: sample_Z(mb_size, Z_dim)})\n",
    "    _, G_loss_curr, g_loss_sum_value = sess.run([G_solver, G_loss, g_loss_sum], feed_dict={Z: sample_Z(mb_size, Z_dim)})\n",
    " \n",
    "    if it%100 ==0: #每过100次记录一下日志，可以通过tensorboard查看\n",
    "        summary_writer.add_summary(dreal_loss_sum_value, it)\n",
    "        summary_writer.add_summary(dfake_loss_sum_value, it)\n",
    "        summary_writer.add_summary(d_loss_sum_value, it)\n",
    "        summary_writer.add_summary(g_loss_sum_value, it)\n",
    " \n",
    "    if it % 1000 == 0: #每训练1000次输出一下结果\n",
    "        save(saver, sess, 'snapshots/', it)\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('D loss: {:.4}'. format(D_loss_curr))\n",
    "        print('G_loss: {:.4}'.format(G_loss_curr))\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
